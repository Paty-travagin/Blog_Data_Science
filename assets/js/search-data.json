{
  
    
        "post0": {
            "title": "Dados de alugueis com Webscrapin",
            "content": "from selenium import webdriver . driver = webdriver.Chrome() driver.get(&#39;https://www.google.com.br&#39;) . barra_pesquisa = driver.find_element_by_xpath(&#39;/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input&#39;) . C: Users User AppData Local Temp/ipykernel_3828/1413251176.py:1: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead barra_pesquisa = driver.find_element_by_xpath(&#39;/html/body/div[1]/div[3]/form/div[1]/div[1]/div[1]/div/div[2]/input&#39;) . barra_pesquisa.send_keys(&#39; dados de imóveis como área total, quantidade de quartos zona da cidade kagle n&#39;) . barra_pesquisa.clear() . resultado = driver.find_element_by_xpath(&#39;/html/body/div[1]&#39;) . C: Users User AppData Local Temp/ipykernel_3828/156612792.py:1: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead resultado = driver.find_element_by_xpath(&#39;/html/body/div[1]&#39;) .",
            "url": "https://paty-travagin.github.io/Blog_Data_Science/2022/06/09/dados_alugueis_webscrapin.html",
            "relUrl": "/2022/06/09/dados_alugueis_webscrapin.html",
            "date": " • Jun 9, 2022"
        }
        
    
  
    
        ,"post1": {
            "title": "Title",
            "content": "Colorindo Imagem . Objetivo . O objetivo deste notebook é servir como um propósito experimental de como o codificador automático mais básico funcionaria em relação à colorização de imagens. Este modelo de auto-encoder é implementado com metodologias de alto nível ou complicadas para resolver a colorização de imagens com excelentes resultados. Mas como será o desempenho do codificador automático mais básico para resolver esse problema é demonstrado aqui. . Referencias . Link for references: https://medium.freecodecamp.org/colorize-b-w-photos-with-a-100-line-neural-network-53d9b4449f8d . https://www.learnopencv.com/convolutional-neural-network-based-image-colorization-using-opencv/ . import numpy as np # linear algebra import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv) import os import cv2 import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from keras.optimizers import Adam from keras import backend as K from keras.layers import Conv2D,MaxPooling2D,UpSampling2D,Input,BatchNormalization,LeakyReLU from keras.layers.merge import concatenate from keras.models import Model from keras.preprocessing.image import ImageDataGenerator from tensorflow import set_random_seed import tensorflow as tf set_random_seed(123) session_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1) sess = tf.Session(graph=tf.get_default_graph(), config=session_conf) tf.keras.backend.set_session(sess) set_random_seed(2) np.random.seed(1) print(os.listdir(&quot;../input/dataset/dataset_updated/&quot;)) . Using TensorFlow backend. . [&#39;training_set&#39;, &#39;validation_set&#39;] . ImagePath=&quot;../input/dataset/dataset_updated/training_set/painting/&quot; . img = cv2.imread(ImagePath+&quot;1179.jpg&quot;) img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) img.shape . (224, 224, 3) . HEIGHT=224 WIDTH=224 ImagePath=&quot;../input/dataset/dataset_updated/training_set/painting/&quot; def ExtractInput(path): X_img=[] y_img=[] for imageDir in os.listdir(ImagePath): try: img = cv2.imread(ImagePath + imageDir) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = img.astype(np.float32) img_lab = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_lab_rs = cv2.resize(img_lab, (WIDTH, HEIGHT)) img_l = img_lab_rs[:,:,0] img_ab = img_lab_rs[:,:,1:] img_ab = img_ab/128 X_img.append(img_l) y_img.append(img_ab) except: pass X_img = np.array(X_img) y_img = np.array(y_img) return X_img,y_img . X_,y_ = ExtractInput(ImagePath) . K.clear_session() def InstantiateModel(in_): model_ = Conv2D(16,(3,3),padding=&#39;same&#39;,strides=1)(in_) model_ = LeakyReLU()(model_) model_ = Conv2D(32,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = MaxPooling2D(pool_size=(2,2),padding=&#39;same&#39;)(model_) model_ = Conv2D(64,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = MaxPooling2D(pool_size=(2,2),padding=&#39;same&#39;)(model_) model_ = Conv2D(128,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = Conv2D(256,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = UpSampling2D((2, 2))(model_) model_ = Conv2D(128,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = UpSampling2D((2, 2))(model_) model_ = Conv2D(64,(3,3), padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) concat_ = concatenate([model_, in_]) model_ = Conv2D(64,(3,3), padding=&#39;same&#39;,strides=1)(concat_) model_ = LeakyReLU()(model_) model_ = BatchNormalization()(model_) model_ = Conv2D(32,(3,3),padding=&#39;same&#39;,strides=1)(model_) model_ = LeakyReLU()(model_) model_ = Conv2D(2,(3,3), activation=&#39;tanh&#39;,padding=&#39;same&#39;,strides=1)(model_) return model_ . Input_Sample = Input(shape=(HEIGHT, WIDTH,1)) Output_ = InstantiateModel(Input_Sample) Model_Colourization = Model(inputs=Input_Sample, outputs=Output_) . LEARNING_RATE = 0.001 Model_Colourization.compile(optimizer=Adam(lr=LEARNING_RATE), loss=&#39;mean_squared_error&#39;) Model_Colourization.summary() . __________________________________________________________________________________________________ Layer (type) Output Shape Param # Connected to ================================================================================================== input_1 (InputLayer) (None, 224, 224, 1) 0 __________________________________________________________________________________________________ conv2d_1 (Conv2D) (None, 224, 224, 16) 160 input_1[0][0] __________________________________________________________________________________________________ leaky_re_lu_1 (LeakyReLU) (None, 224, 224, 16) 0 conv2d_1[0][0] __________________________________________________________________________________________________ conv2d_2 (Conv2D) (None, 224, 224, 32) 4640 leaky_re_lu_1[0][0] __________________________________________________________________________________________________ leaky_re_lu_2 (LeakyReLU) (None, 224, 224, 32) 0 conv2d_2[0][0] __________________________________________________________________________________________________ batch_normalization_1 (BatchNor (None, 224, 224, 32) 128 leaky_re_lu_2[0][0] __________________________________________________________________________________________________ max_pooling2d_1 (MaxPooling2D) (None, 112, 112, 32) 0 batch_normalization_1[0][0] __________________________________________________________________________________________________ conv2d_3 (Conv2D) (None, 112, 112, 64) 18496 max_pooling2d_1[0][0] __________________________________________________________________________________________________ leaky_re_lu_3 (LeakyReLU) (None, 112, 112, 64) 0 conv2d_3[0][0] __________________________________________________________________________________________________ batch_normalization_2 (BatchNor (None, 112, 112, 64) 256 leaky_re_lu_3[0][0] __________________________________________________________________________________________________ max_pooling2d_2 (MaxPooling2D) (None, 56, 56, 64) 0 batch_normalization_2[0][0] __________________________________________________________________________________________________ conv2d_4 (Conv2D) (None, 56, 56, 128) 73856 max_pooling2d_2[0][0] __________________________________________________________________________________________________ leaky_re_lu_4 (LeakyReLU) (None, 56, 56, 128) 0 conv2d_4[0][0] __________________________________________________________________________________________________ batch_normalization_3 (BatchNor (None, 56, 56, 128) 512 leaky_re_lu_4[0][0] __________________________________________________________________________________________________ conv2d_5 (Conv2D) (None, 56, 56, 256) 295168 batch_normalization_3[0][0] __________________________________________________________________________________________________ leaky_re_lu_5 (LeakyReLU) (None, 56, 56, 256) 0 conv2d_5[0][0] __________________________________________________________________________________________________ batch_normalization_4 (BatchNor (None, 56, 56, 256) 1024 leaky_re_lu_5[0][0] __________________________________________________________________________________________________ up_sampling2d_1 (UpSampling2D) (None, 112, 112, 256 0 batch_normalization_4[0][0] __________________________________________________________________________________________________ conv2d_6 (Conv2D) (None, 112, 112, 128 295040 up_sampling2d_1[0][0] __________________________________________________________________________________________________ leaky_re_lu_6 (LeakyReLU) (None, 112, 112, 128 0 conv2d_6[0][0] __________________________________________________________________________________________________ batch_normalization_5 (BatchNor (None, 112, 112, 128 512 leaky_re_lu_6[0][0] __________________________________________________________________________________________________ up_sampling2d_2 (UpSampling2D) (None, 224, 224, 128 0 batch_normalization_5[0][0] __________________________________________________________________________________________________ conv2d_7 (Conv2D) (None, 224, 224, 64) 73792 up_sampling2d_2[0][0] __________________________________________________________________________________________________ leaky_re_lu_7 (LeakyReLU) (None, 224, 224, 64) 0 conv2d_7[0][0] __________________________________________________________________________________________________ concatenate_1 (Concatenate) (None, 224, 224, 65) 0 leaky_re_lu_7[0][0] input_1[0][0] __________________________________________________________________________________________________ conv2d_8 (Conv2D) (None, 224, 224, 64) 37504 concatenate_1[0][0] __________________________________________________________________________________________________ leaky_re_lu_8 (LeakyReLU) (None, 224, 224, 64) 0 conv2d_8[0][0] __________________________________________________________________________________________________ batch_normalization_6 (BatchNor (None, 224, 224, 64) 256 leaky_re_lu_8[0][0] __________________________________________________________________________________________________ conv2d_9 (Conv2D) (None, 224, 224, 32) 18464 batch_normalization_6[0][0] __________________________________________________________________________________________________ leaky_re_lu_9 (LeakyReLU) (None, 224, 224, 32) 0 conv2d_9[0][0] __________________________________________________________________________________________________ conv2d_10 (Conv2D) (None, 224, 224, 2) 578 leaky_re_lu_9[0][0] ================================================================================================== Total params: 820,386 Trainable params: 819,042 Non-trainable params: 1,344 __________________________________________________________________________________________________ . def GenerateInputs(X_,y_): for i in range(len(X_)): X_input = X_[i].reshape(1,224,224,1) y_input = y_[i].reshape(1,224,224,2) yield (X_input,y_input) Model_Colourization.fit_generator(GenerateInputs(X_,y_),epochs=53,verbose=1,steps_per_epoch=38,shuffle=True)#,validation_data=GenerateInputs(X_val, y_val)) . Epoch 1/53 38/38 [==============================] - 5s 135ms/step - loss: 0.0829 Epoch 2/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0220 Epoch 3/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0087 Epoch 4/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0023 Epoch 5/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0020 Epoch 6/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0016 Epoch 7/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0013 Epoch 8/53 38/38 [==============================] - 1s 22ms/step - loss: 0.0013 Epoch 9/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0013 Epoch 10/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0011 Epoch 11/53 38/38 [==============================] - 1s 21ms/step - loss: 9.4652e-04 Epoch 12/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0057 Epoch 13/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0017 Epoch 14/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0010 Epoch 15/53 38/38 [==============================] - 1s 20ms/step - loss: 8.3544e-04 Epoch 16/53 38/38 [==============================] - 1s 21ms/step - loss: 7.2530e-04 Epoch 17/53 38/38 [==============================] - 1s 21ms/step - loss: 9.2169e-04 Epoch 18/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0081 Epoch 19/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0168 Epoch 20/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0089 Epoch 21/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0018 Epoch 22/53 38/38 [==============================] - 1s 21ms/step - loss: 3.2572e-04 Epoch 23/53 38/38 [==============================] - 1s 21ms/step - loss: 2.4323e-04 Epoch 24/53 38/38 [==============================] - 1s 21ms/step - loss: 5.0313e-04 Epoch 25/53 38/38 [==============================] - 1s 21ms/step - loss: 8.9039e-05 Epoch 26/53 38/38 [==============================] - 1s 21ms/step - loss: 2.4255e-04 Epoch 27/53 38/38 [==============================] - 1s 20ms/step - loss: 2.2172e-04 Epoch 28/53 38/38 [==============================] - 1s 21ms/step - loss: 3.2430e-04 Epoch 29/53 38/38 [==============================] - 1s 26ms/step - loss: 2.6563e-04 Epoch 30/53 38/38 [==============================] - 1s 21ms/step - loss: 3.2507e-04 Epoch 31/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0029 Epoch 32/53 38/38 [==============================] - 1s 21ms/step - loss: 3.7298e-04 Epoch 33/53 38/38 [==============================] - 1s 21ms/step - loss: 3.8887e-05 Epoch 34/53 38/38 [==============================] - 1s 21ms/step - loss: 3.4558e-05 Epoch 35/53 38/38 [==============================] - 1s 24ms/step - loss: 1.2646e-04 Epoch 36/53 38/38 [==============================] - 1s 21ms/step - loss: 2.3782e-04 Epoch 37/53 38/38 [==============================] - 1s 21ms/step - loss: 2.2318e-04 Epoch 38/53 38/38 [==============================] - 1s 21ms/step - loss: 2.3907e-04 Epoch 39/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0058 Epoch 40/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0085 Epoch 41/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0089 Epoch 42/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0069 Epoch 43/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0067 Epoch 44/53 38/38 [==============================] - 1s 22ms/step - loss: 0.0067 Epoch 45/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0067 Epoch 46/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0061 Epoch 47/53 38/38 [==============================] - 1s 20ms/step - loss: 0.0110 Epoch 48/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0074 Epoch 49/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0052 Epoch 50/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0043 Epoch 51/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0073 Epoch 52/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0031 Epoch 53/53 38/38 [==============================] - 1s 21ms/step - loss: 0.0018 . &lt;keras.callbacks.History at 0x7fede0713b38&gt; . TestImagePath=&quot;../input/dataset/dataset_updated/training_set/iconography/&quot; . def ExtractTestInput(ImagePath): img = cv2.imread(ImagePath) img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY) img_ = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img_ = cv2.cvtColor(img_, cv2.COLOR_RGB2Lab) img_=img_.astype(np.float32) img_lab_rs = cv2.resize(img_, (WIDTH, HEIGHT)) img_l = img_lab_rs[:,:,0] #img_l -= 50 img_l_reshaped = img_l.reshape(1,224,224,1) return img_l_reshaped . ImagePath=TestImagePath+&quot;15.jpg&quot; image_for_test = ExtractTestInput(ImagePath) Prediction = Model_Colourization.predict(image_for_test) Prediction = Prediction*128 Prediction=Prediction.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath+&quot;15.jpg&quot;) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed65335e10&gt; . ImagePath=TestImagePath+&quot;314.jpg&quot; image_for_test = ExtractTestInput(ImagePath) Prediction_1 = Model_Colourization.predict(image_for_test) Prediction_1 = Prediction_1*128 Prediction_1=Prediction_1.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath+&quot;314.jpg&quot;) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction_1 img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed65246710&gt; . ImagePath=TestImagePath+&quot;698.jpg&quot; image_for_test = ExtractTestInput(ImagePath) Prediction_2 = Model_Colourization.predict(image_for_test) Prediction_2 = Prediction_2*128 Prediction_2=Prediction_2.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath+&quot;698.jpg&quot;) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction_2 img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed651518d0&gt; . TestImagePath=&quot;../input/dataset/dataset_updated/training_set/sculpture/240.jpg&quot; image_for_test = ExtractTestInput(TestImagePath) Prediction_3 = Model_Colourization.predict(image_for_test) Prediction_3 = Prediction_3*128 Prediction_3=Prediction_3.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction_3 img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed65052c88&gt; . TestImagePath=&quot;../input/dataset/dataset_updated/training_set/painting/1601.jpg&quot; image_for_test = ExtractTestInput(TestImagePath) Prediction_4 = Model_Colourization.predict(image_for_test) Prediction_4 = Prediction_4*128 Prediction_4=Prediction_4.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction_4 img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed64f63b38&gt; . TestImagePath=&quot;../input/dataset/dataset_updated/training_set/painting/1577.jpg&quot; image_for_test = ExtractTestInput(TestImagePath) Prediction_5 = Model_Colourization.predict(image_for_test) Prediction_5 = Prediction_5*128 Prediction_5=Prediction_5.reshape(224,224,2) . plt.figure(figsize=(30,20)) plt.subplot(5,5,1) img = cv2.imread(TestImagePath) img_1 = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) img = cv2.cvtColor(img_1, cv2.COLOR_RGB2GRAY) img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB) img = cv2.resize(img, (224, 224)) plt.imshow(img) plt.subplot(5,5,1+1) img_ = cv2.cvtColor(img, cv2.COLOR_RGB2Lab) img_[:,:,1:] = Prediction_5 img_ = cv2.cvtColor(img_, cv2.COLOR_Lab2RGB) plt.title(&quot;Predicted Image&quot;) plt.imshow(img_) plt.subplot(5,5,1+2) plt.title(&quot;Ground truth&quot;) plt.imshow(img_1) . &lt;matplotlib.image.AxesImage at 0x7fed64df3cf8&gt; . CONCLUSION O modelo é capaz de identificar o padrão correto ou tons em que a cor deve ser preenchida ou podemos dizer que o modelo é capaz de separar as partes que precisam ser coloridas para obter a imagem colorida, mas não é capaz de prever a precisão cor para aquela sombra ou porção o tempo todo em relação à imagem real. .",
            "url": "https://paty-travagin.github.io/Blog_Data_Science/2022/06/09/colorir_imagem_pt_br.html",
            "relUrl": "/2022/06/09/colorir_imagem_pt_br.html",
            "date": " • Jun 9, 2022"
        }
        
    
  
    
        ,"post2": {
            "title": "Análise Exploratória de Dados de pessoas com Câncer.",
            "content": "Importando Bibliotecas . !pip install openpyxl import pandas as pd import numpy as np import seaborn as sns import matplotlib.pyplot as plt from sklearn.linear_model import LinearRegression from sklearn.model_selection import train_test_split from openpyxl import load_workbook import matplotlib.pyplot as plt . Requirement already satisfied: openpyxl in /usr/local/lib/python3.7/dist-packages (3.0.9) Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.7/dist-packages (from openpyxl) (1.1.0) . Abrindo o arquivo csv . data = pd.read_excel(&#39;/content/cancer patient data sets.xlsx&#39;) . data.head(5) . Patient Id Age Gender Air Pollution Alcohol use Dust Allergy OccuPational Hazards Genetic Risk chronic Lung Disease Balanced Diet ... Fatigue Weight Loss Shortness of Breath Wheezing Swallowing Difficulty Clubbing of Finger Nails Frequent Cold Dry Cough Snoring Level . 0 P1 | 33 | 1 | 2 | 4 | 5 | 4 | 3 | 2 | 2 | ... | 3 | 4 | 2 | 2 | 3 | 1 | 2 | 3 | 4 | Low | . 1 P10 | 17 | 1 | 3 | 1 | 5 | 3 | 4 | 2 | 2 | ... | 1 | 3 | 7 | 8 | 6 | 2 | 1 | 7 | 2 | Medium | . 2 P100 | 35 | 1 | 4 | 5 | 6 | 5 | 5 | 4 | 6 | ... | 8 | 7 | 9 | 2 | 1 | 4 | 6 | 7 | 2 | High | . 3 P1000 | 37 | 1 | 7 | 7 | 7 | 7 | 6 | 7 | 7 | ... | 4 | 2 | 3 | 1 | 4 | 5 | 6 | 7 | 5 | High | . 4 P101 | 46 | 1 | 6 | 8 | 7 | 7 | 7 | 6 | 7 | ... | 3 | 2 | 4 | 1 | 4 | 2 | 4 | 2 | 3 | High | . 5 rows × 25 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; data.describe() . Age Gender Air Pollution Alcohol use Dust Allergy OccuPational Hazards Genetic Risk chronic Lung Disease Balanced Diet Obesity ... Coughing of Blood Fatigue Weight Loss Shortness of Breath Wheezing Swallowing Difficulty Clubbing of Finger Nails Frequent Cold Dry Cough Snoring . count 1000.000000 | 1000.000000 | 1000.0000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | ... | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | 1000.000000 | . mean 37.174000 | 1.402000 | 3.8400 | 4.563000 | 5.165000 | 4.840000 | 4.580000 | 4.380000 | 4.491000 | 4.465000 | ... | 4.859000 | 3.856000 | 3.855000 | 4.240000 | 3.777000 | 3.746000 | 3.923000 | 3.536000 | 3.853000 | 2.926000 | . std 12.005493 | 0.490547 | 2.0304 | 2.620477 | 1.980833 | 2.107805 | 2.126999 | 1.848518 | 2.135528 | 2.124921 | ... | 2.427965 | 2.244616 | 2.206546 | 2.285087 | 2.041921 | 2.270383 | 2.388048 | 1.832502 | 2.039007 | 1.474686 | . min 14.000000 | 1.000000 | 1.0000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | ... | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | 1.000000 | . 25% 27.750000 | 1.000000 | 2.0000 | 2.000000 | 4.000000 | 3.000000 | 2.000000 | 3.000000 | 2.000000 | 3.000000 | ... | 3.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | 2.000000 | . 50% 36.000000 | 1.000000 | 3.0000 | 5.000000 | 6.000000 | 5.000000 | 5.000000 | 4.000000 | 4.000000 | 4.000000 | ... | 4.000000 | 3.000000 | 3.000000 | 4.000000 | 4.000000 | 4.000000 | 4.000000 | 3.000000 | 4.000000 | 3.000000 | . 75% 45.000000 | 2.000000 | 6.0000 | 7.000000 | 7.000000 | 7.000000 | 7.000000 | 6.000000 | 7.000000 | 7.000000 | ... | 7.000000 | 5.000000 | 6.000000 | 6.000000 | 5.000000 | 5.000000 | 5.000000 | 5.000000 | 6.000000 | 4.000000 | . max 73.000000 | 2.000000 | 8.0000 | 8.000000 | 8.000000 | 8.000000 | 7.000000 | 7.000000 | 7.000000 | 7.000000 | ... | 9.000000 | 9.000000 | 8.000000 | 9.000000 | 8.000000 | 8.000000 | 9.000000 | 7.000000 | 7.000000 | 7.000000 | . 8 rows × 23 columns . &lt;svg xmlns=&quot;http://www.w3.org/2000/svg&quot; height=&quot;24px&quot;viewBox=&quot;0 0 24 24&quot; width=&quot;24px&quot;&gt; &lt;/svg&gt; Verificando o tipo de dados . data.info() . &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; RangeIndex: 1000 entries, 0 to 999 Data columns (total 25 columns): # Column Non-Null Count Dtype -- -- 0 Patient Id 1000 non-null object 1 Age 1000 non-null int64 2 Gender 1000 non-null int64 3 Air Pollution 1000 non-null int64 4 Alcohol use 1000 non-null int64 5 Dust Allergy 1000 non-null int64 6 OccuPational Hazards 1000 non-null int64 7 Genetic Risk 1000 non-null int64 8 chronic Lung Disease 1000 non-null int64 9 Balanced Diet 1000 non-null int64 10 Obesity 1000 non-null int64 11 Smoking 1000 non-null int64 12 Passive Smoker 1000 non-null int64 13 Chest Pain 1000 non-null int64 14 Coughing of Blood 1000 non-null int64 15 Fatigue 1000 non-null int64 16 Weight Loss 1000 non-null int64 17 Shortness of Breath 1000 non-null int64 18 Wheezing 1000 non-null int64 19 Swallowing Difficulty 1000 non-null int64 20 Clubbing of Finger Nails 1000 non-null int64 21 Frequent Cold 1000 non-null int64 22 Dry Cough 1000 non-null int64 23 Snoring 1000 non-null int64 24 Level 1000 non-null object dtypes: int64(23), object(2) memory usage: 195.4+ KB . Verificando valores nulos . data.isnull().sum() . Patient Id 0 Age 0 Gender 0 Air Pollution 0 Alcohol use 0 Dust Allergy 0 OccuPational Hazards 0 Genetic Risk 0 chronic Lung Disease 0 Balanced Diet 0 Obesity 0 Smoking 0 Passive Smoker 0 Chest Pain 0 Coughing of Blood 0 Fatigue 0 Weight Loss 0 Shortness of Breath 0 Wheezing 0 Swallowing Difficulty 0 Clubbing of Finger Nails 0 Frequent Cold 0 Dry Cough 0 Snoring 0 Level 0 dtype: int64 . Rela&#231;&#227;o entre idade e nivel do c&#226;ncer . X = data[&quot;Age&quot;].values Y = data[&quot;Level&quot;].values line_plot = sns.barplot(X,Y) line_plot.set_xlabel(&quot;Age&quot;, fontsize = 15,color=&quot;skyblue&quot;) line_plot.set_ylabel(&quot;Level&quot;, fontsize = 15,color=&quot;skyblue&quot;) . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . Text(0, 0.5, &#39;Level&#39;) . Rela&#231;&#227;o entre Idade &amp; smoking(Fumar) . Analisando o gr&#225;fico acima percebe que pessoas a partir dos . 36 anos tem c&#226;ncer nivel Medium e High. . X = data[&quot;Age&quot;].values Y = data[&quot;Smoking&quot;].values line_plot = sns.lineplot(X,Y) line_plot.set_xlabel(&quot;Age&quot;, fontsize = 15,color=&quot;skyblue&quot;) line_plot.set_ylabel(&quot;Smoking&quot;, fontsize = 15,color=&quot;skyblue&quot;) . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . Text(0, 0.5, &#39;Smoking&#39;) . Sobre o gráfico acima, pessoas entre 30 e 40 anos e pessoas a partir dos 60 fumam mais. . risco generico x idade . X = data[&quot;Age&quot;].values Y = data[&quot;Genetic Risk&quot;].values line_plot = sns.lineplot(X,Y) line_plot.set_xlabel(&quot;Age&quot;, fontsize = 15,color=&quot;skyblue&quot;) line_plot.set_ylabel(&quot;Genetic Risk&quot;, fontsize = 15,color=&quot;skyblue&quot;) . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . Text(0, 0.5, &#39;Genetic Risk&#39;) . Sobre o gr&#225;fico acima, Pessoas acima de 55 anos tem um risco generico mais alto. . Age &amp; Fatigue . X = data[&quot;Age&quot;].values Y = data[&quot;Fatigue&quot;].values line_plot = sns.lineplot(X,Y) line_plot.set_xlabel(&quot;Age&quot;, fontsize = 15,color=&quot;skyblue&quot;) line_plot.set_ylabel(&quot;Fatigue&quot;, fontsize = 15,color=&quot;skyblue&quot;) . /usr/local/lib/python3.7/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation. FutureWarning . Text(0, 0.5, &#39;Fatigue&#39;) . Sobre o gr&#225;fico acima, pessoas &#224; partir dos 54 anos sofrem mais com Fatigue. . Age &amp; Alcohol use . sns.relplot(x=&quot;Age&quot;,y=&quot;Alcohol use&quot;, data=data, hue=&quot;Level&quot;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f5f72500dd0&gt; . Analisando o gr&#225;fic acima, percebe que, pessoas que usam muito alcohol . tem c&#226;n&#231;er High. . Age &amp; Alcohol &amp; Gender . sns.relplot(x=&quot;Age&quot;,y=&quot;Alcohol use&quot;, data=data, hue=&quot;Gender&quot;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f5f7248c910&gt; . Calculando a m&#233;dia do level/ plotando um grafico . mediun_level = data.groupby(&quot;Level&quot;).mean() sns.relplot(x=&quot;Age&quot;, y=&quot;Alcohol use&quot;,data= mediun_level,hue=&quot;Level&quot;, alpha =0.8, palette=&quot;muted&quot;, height = 6) . &lt;seaborn.axisgrid.FacetGrid at 0x7f5f781fd250&gt; . Sobre o gr&#225;fico acima, diz que, pessoas com level Low, tem m&#233;dia de 37 anos. . media de level x falta de ar . grouped_by_level = data.groupby(&quot;Level&quot;).mean() sns.relplot(x=&quot;Age&quot;, y=&quot;Shortness of Breath&quot;,data= grouped_by_level,hue=&quot;Level&quot;) . &lt;seaborn.axisgrid.FacetGrid at 0x7f5f721a30d0&gt; . Sobre o gr&#225;fico acima, as pessoas com Level LOW e MEDIUM sofrem de falta de ar. .",
            "url": "https://paty-travagin.github.io/Blog_Data_Science/2022/06/09/An%C3%A1lise_Exploratoria_C%C3%A2ncer-(1).html",
            "relUrl": "/2022/06/09/An%C3%A1lise_Exploratoria_C%C3%A2ncer-(1).html",
            "date": " • Jun 9, 2022"
        }
        
    
  
    
        ,"post3": {
            "title": "Api com Python",
            "content": "Importando bibliotecas . import requests import json . Para criar esse c&#243;digo primeiro precisa pegar o link na pagina da web (https://docs.awesomeapi.com.br/api-cep) . Transformar em jason e retornar os campos que deseja. . cotacoes = requests.get(&#39; https://economia.awesomeapi.com.br/last/USD-BRL,EUR-BRL,BTC-BRL&#39;) cotacoes= cotacoes.json() cotacao_dolar = cotacoes[&#39;USDBRL&#39;][&#39;bid&#39;] print(cotacao_dolar) . 4.8746 . cep=requests.get(&#39; https://cep.awesomeapi.com.br/json/05424020&#39;) cep= cep.json() cp= cep[&#39;cep&#39;] rua= cep[&#39;district&#39;] nome_rua=[&#39;address_name&#39;] city= cep[&#39;city&#39;] state= cep[&#39;state&#39;] print(cp) print(rua) print(nome_rua) print(city) print(state) . 05424020 Pinheiros [&#39;address_name&#39;] São Paulo SP .",
            "url": "https://paty-travagin.github.io/Blog_Data_Science/2022/06/09/API_PYTHON-(1).html",
            "relUrl": "/2022/06/09/API_PYTHON-(1).html",
            "date": " • Jun 9, 2022"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://paty-travagin.github.io/Blog_Data_Science/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://paty-travagin.github.io/Blog_Data_Science/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}